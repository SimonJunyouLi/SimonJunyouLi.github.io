---
title: PoseGPT - Chatting about 3D Human Pose
# subtitle: My summary notes of the PostGPT paper. 
authors: Yao Feng, Jing Lin, Sai Kumar Dwivedi, Yu Sun, Priyanka Patel, Michael J. Black
layout: default
date: 2024-03-07
keywords: machine learning
tags: ml
published: true
---

Motivated by human's ability to intuitively understand postures from either images or textual descriptions, this work aims to develop a multi-modal LLM for pose, **PostGPT**. Traditional approaches on pose estimations are proven to lack *holistic scene comprehension* and *nuanced reasoning*, leading to a disconncect between visual data and its real world implications. PostGPT addresses issue by embedding SMPL poses as a distinct signal token in a multi-model LLM, empowering LLM to apply their world knowledge in reasoning about human poses. The results show that PoseGPT outperforms existing multi-modal LLMs, opening new directions on pose analysis. 

## Introduction

Traditional 3D human pose estimation can be categorized into two methods based on the input modality:
- **Image**: this method usually detects individuals from the picture and segments them from the image, then uses a NN to predict the 3D pose and shape. However, it often lacks contextual awareness, missing out on information on a holistic understanding of the scene and the interactions between human with themselves and the environment. 
- **text**: the instructions for this method are typically very explicit, with the text describing desired actions. However, this method is limited as the training data is scarce. 

Therefore, the existing specialized systems are very narrow tasked, contrary to what the authors perception on the ability of the LLMs. The authors hypothesize that, due to LLMs ability to perceive and interpret information based on their world knowledge, if LLMs can relate their knowledge to 3D human pose, then they would be very powerful, performing beyond existing solutions. 

To evaluate what LLMs already understand about 3D pose generation and how we can teach them, the authors propose **PoseGPT**, fine-tuning multi-modal LLMs for predicting human pose represented as SMPL. A special \<POSE\> token is generated in LLMs' output, representing the SMPL poses. The language embedding is extracted from the token, later fed into a MLP to predict SMPL pose parameters. 

The contributions of the paper can be summarized as follows:
1. Propose PoseGPT, a multi-modal LLM directly generating SMLP poses
2. Introduce two innovative tasks
    - **Speculative Pose Generation (SPG)**: in this task, LLMs are asked to speculate, which requires it to have the understanding of
        * what being *adjective* means
        * how does this translate into 3D pose
    - **Reasoning-based Pose Estimation (RPE)**: contrary to conventional approach where LLMs are provided with a bounding box, PoseGPT is exposed to the entire scene, gaining information regrading the context. 
3. Demonstrates superior performance compared to other LLMs based results


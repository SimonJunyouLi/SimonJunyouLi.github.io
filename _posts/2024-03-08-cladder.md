---
title: PoseGPT - Chatting about 3D Human Pose
# subtitle: My summary notes of the PostGPT paper. 
authors: Yao Feng, Jing Lin, Sai Kumar Dwivedi, Yu Sun, Priyanka Patel, Michael J. Black
layout: default
date: 2024-03-07
keywords: machine learning
tags: ml
published: true
---

## Abstract

Previous work on NLP focuses mostly on evaluating *commonsense* causal reasoning in LLMs. This work attempts to evalute LLMs ability to perform causal inference in accordance with a set of well-defined **formal-rules**, composing a large dataset "CLadder" with 10k samples. CLadder is based on a collection of causal graphs and queries (associational, interventional, and counterfactual). The paper also proposes a bespoke chain-of-thought prompting strategy, CausalCoT.

## Introduction

Recent advances in LLMs shift the public's attention to their capability in performing sound *causal reasoning* and answering causal questinos at scale with ease. This raises the question: "*Do LLMs understand causality?*".

Majority of previous work focus on ***commonsense causality***, exploring LLMs as *knowledge bases*. This assesses the alignment between commonsense knowledge about causal relatinoship in LLMs. However, few studies have focused on the capability of ***causal reasoning***. A lot of the times the LLMs would just be "*causal parrots*" that perform unreliable *amortized causal inference*", answering using repeated patterns in training data. 

Therefore, the authors introduce a dataset **CLadder** to evaluate the *formal causal reasoning* in lLMs. The dataset contain 10k causal questions that cover all three rungs of the *Ladder of Causation*: **Associational**; **Interventional**; **Counterfactual**. In addition, to probe whether LLMs employ *amortized causal inference*, the dataset contains nonsensical causal relations where amortized causal inference would fail while formal causal reasoning would still yield correct answers. 

Moreover, the author proposes a method to elicit sound causal reasoning in LLMs and help them solve challenging causality questions with **CausalCoT**, a chain-of-thought prompting strategy. This strategy improves the performance of vanilla GPT-4 by 8.37% on CLadder to 70.40%.

To summarzie, the contributions of this paper are as follows:
1. Introduces **CLadder**, a dataset for formal causal reasoning with 10k causal questions, spanning all three rungs of the ladder of causations, several causal graphs, and various stories for verbalization.
2. Develops **CausalCoT**, a chain-of-thought prompting strategy to elicit formal causal reasoning in LLMs. 
3. Assesses eight LLMs, showcasing the limitations of lLMs in formal causal reasoning. 